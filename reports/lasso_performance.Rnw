%  SET UP LaTeX DEFAULTS  --------------------------------------
\documentclass{article}
\usepackage[sc]{mathpazo}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{3}
% \usepackage[options]{algorithm2e}
\usepackage{url}
\usepackage{setspace}
\usepackage{relsize}
\usepackage{float}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{booktabs}

\usepackage[authoryear]{natbib}
\usepackage[nottoc]{tocbibind}
\usepackage[unicode=true,pdfusetitle,bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks,citecolor=black,filecolor=black,linkcolor=black,urlcolor=black]{hyperref}
\hypersetup{
    pdfstartview={XYZ null null 1}}
%\usepackage{breakurl}
\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}
\usepackage[buttonsize=1em]{animate}
\makeatother
\renewcommand{\bibname}{References}

\begin{document}

\title{Sparse Undirected Graphs for Spatiotemporal Modeling: Summary of LASSO Performance}
\author{Robert A. Giaquinto}
\maketitle

\begin{abstract}
   Abstract goes here!
\end{abstract}

\tableofcontents

%  Base KnitR code ------------------------------------------------------------------
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)

opts_chunk$set(fig.align='center',
    fig.show='hold',
    fig.pos='H',
    message=FALSE,
    warning=FALSE,
    echo=FALSE,
    par=TRUE)
options(width=80, stringsAsFactors=FALSE)

library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(xtable)
library(stringr)
library(readr)
library(glmnet)
library(glmnetUtils)
library(lubridate)
library(RColorBrewer)
library(ggmap)
library(geoR)

source_dir <- '/Users/robert/documents/umn/air_pollution/src/main/'
source(paste0(source_dir, 'Utility_Functions.R'))
source(paste0(source_dir, 'Lasso.R'))
@


\section{Overview}
This is what I found



% IMPORT DATA
<<data, results='hide'>>=

data_dir <- '/Users/robert/documents/umn/air_pollution/data/'

# read in a few rows of data to determine column types
temp <- read.csv(file=paste0(data_dir, "houston_features.csv"), nrow=1000)

# if column types are logical (from poor guessing of type) change to double
col_types <- sapply(temp, class)
col_types <- ifelse(col_types %in% c('logical', 'numeric'), 'd', str_sub(col_types,1,1))
col_types <- paste(col_types, collapse='')

DF <- read_csv(file=paste0(data_dir, "houston_features.csv"),
    progress=FALSE,
    col_types=col_types)
# remove temporary items
rm(temp, col_types)

# to speed up exploration, only use data from 2010 forward
full_locations <- c(167001034L, 201000024L, 201001034L,
    201001035L, 201001039L, 201001042L, 201001050L, 245000022L, 245001050L)
DF <- as.data.frame(DF[DF$date_key >= 20100000 & DF$location_key %in% full_locations,])
DF$County_Code <- NULL
DF$State_Code <- NULL

# Create a few custom variables
DF$am_rushhour <- ifelse(DF$Time_Local %in% c(6,7,8), 1, 0)
DF$pm_rushhour <- ifelse(DF$Time_Local %in% c(18,19,20,21), 1, 0)
DF$rushhour <- ifelse(DF$am_rushhour > 0 | DF$pm_rushhour > 0, 1, 0)
@

<<var_names>>=
# define variables to refer to groups of variables
tar_var <- 'pm25'

key_vars <- c("date_key", "datetime_key", "location_key"
#     , "Date_Local"
    , "Latitude"
    , "Longitude"
#     , "Site_Num"
    , "Time_Local"
)

date_vars <- c("day_of_week_cycle",
    "day_of_week_0", "day_of_week_1", "day_of_week_2",
    "day_of_week_3", "day_of_week_4", "day_of_week_5", "day_of_week_6",
    "day_of_year_cycle", "week_of_year_cycle",
    "month_cycle", "month_1",
    "month_2", "month_3", "month_4", "month_5", "month_6", "month_7",
    "month_8", "month_9", "month_10", "month_11", "month_12",
    "day_of_month_cycle",
    "quarter_cycle", "quarter_1", "quarter_2", "quarter_3", "quarter_4",
    "time_cycle",
    "am_rushhour", "pm_rushhour", "rushhour"
)

lag_root_names <- c("pm25_lag", "wind_direction_sin_lag", "wind_direction_cos_lag",
    # "wind_direction_NE_lag", "wind_direction_SE_lag",
    # "wind_direction_NW_lag", "wind_direction_SW_lag",
    "wind_knots_lag", "temperature_lag",
    "pct_humidity_lag", "dewpoint_lag",
    "ozone_lag", "so2_lag", "co_lag", "no2_lag")

lag_vars <- c(paste0(lag_root_names, "1")
#     , paste0(lag_root_names, "2")
#     , paste0(lag_root_names, "3")
)

agg_vars <- c(paste0(lag_root_names, "1", "_agg1")
#     , paste0(lag_root_names, "2", "_agg1")
#     , paste0(lag_root_names, "3", "_agg1")
)

# keep only the variables used above for modeling
DF <- DF[,c(key_vars, tar_var, date_vars, lag_vars, agg_vars)]

# impute remainder of missings
for (n in names(DF)) {
    if (n %in% c(lag_vars, agg_vars)) {
        DF[is.na(DF[,n]), n] <- mean(DF[,n], na.rm=TRUE)
    }
}
@




\section{Introduction}

<<training_parameters>>=
testing_months=6
training_months=12
verbose=FALSE
num_lambdas <- 25
var_list <- list(tar_var=tar_var, date_vars=date_vars, agg_vars=agg_vars, lag_vars=lag_vars)
cov_methods = c("pearson", "spearman")
@





\section{Error as a Function of Model Complexity}
<<lasso>>=
lasso_results <- Lasso(DF, var_list,
    num_lambdas=num_lambdas,
    testing_months=testing_months,
    training_months=training_months, verbose=verbose)

@

What do the model errors look like for known locations and future dates?
<<known_error>>=
p1 <- plot_error_curve(lasso_results, "future")
print(p1)
@


What do the model errors look like for known locations and future dates?
<<unknown_error>>=
p1 <- plot_error_curve(lasso_results, "unknown")
print(p1)
@




\section{Distribution of Error Across Time and Space}
Plot distribution of error across locations, and plot error distributions varied by window time periods.
<<win_loc_plots, out.width='.49\\textwidth'>>=
plot_error_distribution(lasso_results, split_by="location")
plot_error_distribution(lasso_results, split_by="window")
@



Print out error for each location of unknown test set.
<<lasso_location_error_table, results='asis'>>=
key_vars <- c("location", "datetime_key", "window", "set", "actual")
keep_vars <- c(key_vars, paste0(c("predict", "error"),
    which(lasso_results$best_lambda == lambda_sequence(num_lambdas)))) # index of best lambda
best_errors <- as.data.frame(lasso_results$all_hourly_df[,keep_vars])
names(best_errors) <- c(key_vars, "predict", "error")

# what is the predicted error at each location (for optimal lambda)
loc_error <- best_errors[best_errors$set == "unknown",] %>% group_by(location) %>%
    summarise(avg_actual = mean(actual), avg_predict = mean(predict), RMSE=rmse(error))
loc_error <- loc_error[order(loc_error$RMSE, decreasing=FALSE),]
print(xtable(loc_error, digits=4), include.rownames=FALSE)
rm(loc_error)
@

<<lasso_window_error_table, results='asis'>>=
# what is the predicted error at each location (for optimal lambda)
window_error <- best_errors[best_errors$set == "unknown",] %>% group_by(window) %>%
    summarise(avg_actual = mean(actual), avg_predict = mean(predict), RMSE=rmse(error))
window_error <- window_error[order(window_error$RMSE, decreasing=FALSE),]
print(xtable(window_error, digits=4), include.rownames=FALSE)
rm(window_error)
@



\section{Spatial Correlation}
Are the errors correlated?
<<error_correlation, out.width='.49\\textwidth'>>=
p1 <- plot_spatial_correlation_Lasso(best_errors, "unknown")
map_df <- unique(DF[,c("Latitude", "Longitude", "location_key")])
map_df$location_key <- factor(map_df$location_key)
names(map_df) <- c("lat", "lon", "location")
map <- get_map(location = c(lon=mean(map_df$lon), lat=mean(map_df$lat)),
    zoom=9, maptype="toner-lite", color="bw", messaging=FALSE)
p2 <- ggmap(map) +
    geom_point(data=map_df,
        aes(x=lon, y=lat, colour=location), size=4) +
    labs(x="Longitude", y="Latitude")

print(p1)
print(p2)

@


How about for the training locations?
<<future_error_correlation, out.width='.49\\textwidth'>>=
p1 <- plot_spatial_correlation_Lasso(best_errors, "future")
print(p1)
print(p2)
@
Correlation structure looks about the same.




\section{Spatial Interpolation}
Use krigging to interpolate locations
<<lasso_krig>>=
lat_long_df <- DF %>% group_by(location_key) %>% summarise(lat=mean(Latitude), lon=mean(Longitude))
aday <- best_errors[best_errors$set == "future" &
        best_errors$datetime_key >= 2013010200 &
        best_errors$datetime_key < 2013010300,]
krig_df <- left_join(x=aday, y=lat_long_df, by=c("location"="location_key"))
krig_df <- krig_df[,c("lat","lon","predict")]

# a <- read.table("http://www.stat.ucla.edu/~nchristo/statistics_c173_c273/kriging_11.txt", header=TRUE)
b <- as.geodata(krig_df)
b <- jitterDupCoords(x=b, max=.05)
prediction <- ksline(b, cov.model="exp",
    cov.pars=c(10,3.33), nugget=0,
    locations=c(29.90104,-95.32613))

n <- 25
x <- seq(min(krig_df$lat), max(krig_df$lat), length.out=n)
y <- seq(min(krig_df$lon), max(krig_df$lon), length.out=n)
xv <- rep(x, n)
yv <- rep(y, each=n)
in_mat <- as.matrix(cbind(xv,yv))
q <- ksline(b, cov.model="gaussian",cov.pars=c(2,.1), locations=in_mat)
cbind(q$predict[1:5], q$krige.var[1:5])
image(q, val=q$predict)
points(krig_df)


@



\section{Temporal Correlation}
Are the errors correlated with time?
<<time_errors>>=
# aggregate results by day
best_errors$datetime <- parse_date_time(best_errors$datetime_key, "%y%m%d%H")
hour(best_errors$datetime) <- 0
agg_df <- best_errors[best_errors$set == "unknown",] %>% group_by(datetime) %>%
    summarise(RMSE = rmse(error))
ggplot(agg_df, aes(x=datetime, y=RMSE)) +
    geom_point(colour="grey") +
    geom_line(colour="grey") +
    geom_smooth(se=FALSE, colour="black") +
    stat_smooth(method = "lm") +
    theme_bw()


@



\end{document}